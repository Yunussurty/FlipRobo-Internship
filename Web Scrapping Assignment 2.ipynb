{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping Assignment 2(Selenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import  NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering details in search criteria for designations\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Analyst')\n",
    "\n",
    "#Entering deatils in loaction field\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the tages with the job titles.\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "    Job=job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Senior Data Analyst - Data Lineage',\n",
       " 'Data analysts',\n",
       " 'Excel VBA Jobs Bangalore | VBA data analyst Jobs',\n",
       " 'Data Analyst (2positions)//immediate Joiners//bangalore',\n",
       " 'Data analysts',\n",
       " 'Business Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Mysore/Mysuru, Coimbatore, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job location.\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags:\n",
    "    job_location.append(i.text)\n",
    "    loc=job_location[:10]\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Opex Global Services',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Mind Circus Innovation',\n",
       " 'Tech Mahindra Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'dotSolved India Pvt., Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the company names.\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "    com=company_name[:10]\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-6 Yrs',\n",
       " '0-1 Yrs',\n",
       " '4-8 Yrs',\n",
       " '3-5 Yrs',\n",
       " '9-13 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '1-4 Yrs']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the experince required.\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "for i in exp_tags:\n",
    "    experience_required.append(i.text)\n",
    "    exp=experience_required[:10]\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Opex Global Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst - Data Lineage</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>Mysore/Mysuru, Coimbatore, Bangalore/Bengaluru</td>\n",
       "      <td>Mind Circus Innovation</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excel VBA Jobs Bangalore | VBA data analyst Jobs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst (2positions)//immediate Joiners//...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>dotSolved India Pvt., Ltd.</td>\n",
       "      <td>9-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1    Data Scientist / Data Analyst -Business Analyst   \n",
       "2                 Senior Data Analyst - Data Lineage   \n",
       "3                                      Data analysts   \n",
       "4   Excel VBA Jobs Bangalore | VBA data analyst Jobs   \n",
       "5  Data Analyst (2positions)//immediate Joiners//...   \n",
       "6                                      Data analysts   \n",
       "7                              Business Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bengaluru/Bangalore   \n",
       "3     Mysore/Mysuru, Coimbatore, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6   Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              Company Experience Required  \n",
       "0  Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                Opex Global Services            5-10 Yrs  \n",
       "2              IBM India Pvt. Limited             5-6 Yrs  \n",
       "3              Mind Circus Innovation             0-1 Yrs  \n",
       "4                  Tech Mahindra Ltd.             4-8 Yrs  \n",
       "5              IBM India Pvt. Limited             3-5 Yrs  \n",
       "6          dotSolved India Pvt., Ltd.            9-13 Yrs  \n",
       "7            Myntra Designs Pvt. Ltd.             3-5 Yrs  \n",
       "8            Myntra Designs Pvt. Ltd.             3-8 Yrs  \n",
       "9            Myntra Designs Pvt. Ltd.             1-4 Yrs  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Analyst={'Job':Job,'Location':loc,\n",
    "              'Company':com,'Experience Required':exp}\n",
    "Data_Analyst=pd.DataFrame(data=Data_Analyst)\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering details in search criteria for designations\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "#Entering deatils in loaction field\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "job=[]\n",
    "loc=[]\n",
    "comp=[]\n",
    "desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Senior Data Scientist',\n",
       " 'Immediate job opening - Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'VP - Sr. Data Scientist For Morgan Stanley, Bangalore',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'data scientist',\n",
       " 'Data analytics / Data scientist intern (work from Home)']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job titles.\n",
    "\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title:\n",
    "    job.append(i.text)\n",
    "    job=job[:10]\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=driver.find_element_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Bangalore/Bengaluru, Delhi / NCR']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job location.\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in locations:\n",
    "    loc.append(i.text)\n",
    "loc=loc[:10]\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'RedBus',\n",
       " 'RedBus',\n",
       " 'Fractal Analytics',\n",
       " 'Morgan Stanley Advantage Services',\n",
       " 'bd',\n",
       " 'FICO',\n",
       " 'Fractal Analytics',\n",
       " 'Global Talent Pool',\n",
       " 'TalkValley LLC']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the company names.\n",
    "company=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company:\n",
    "    comp.append(i.text)\n",
    "    \n",
    "comp=comp[:10]\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please note that you have to scrape full job description. For that you may have to open each job separately as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job Role : Data Scientist/Data Analyst /Business Analyst\\n\\nLocation : Chennai/Bangalore/Hyderabad/Pune/Mumbai/Delhi\\n\\nGreetings from CAIA - Center for Artificial Intelligence & Advanced Analytics\\n43% of companies experienced a high deficit of skilled resources with Advanced Analytical skills and AI implementing capabilities in year 2020. CAIA gives you a great opportunity to enter the world of future technologies and Innovations- Data Science, Analytics, AI, Data Visualization and Cloud Computing.\\n\\nWhile 2020 was a year like no other, we are living in an interesting times where data is reshaping the world, and businesses are rapidly adopting technology to gain an edge over others. Hence, there's a substantial increase in demand for technology professionals who can implement systems in data science, machine learning and AI in Tier 1 and Tier 2 organization's working closely with us.\\n\\nTo help you build a sustainable career we would like you to utilize data, software and Analytical approaches in Data Science and AI to up skill and get recruited into an organization appreciating your skilling journey.\\nApplications invited from all Freshers and experienced candidates (0-3 yrs) aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science.\\nIf you wish to make a shift in your career or undergo a career transition, upskilling is essential since it allows you to learn more about the domain and acquire the required skills.\\n\\nCall to schedule interview Monday -Saturday from 10:00 am to 7Pm\\n\\nAlexandria A - +91 76958 88879\\nManigandan -+91 93444 57360\\n\\nEmail :\\n\\nalexandriaa@centerforaia.com\\nmanigandan@centerforaia.com\\n\\nWhat is needed from you?\\n\\nFreshers who wish to start their career in Analytics and AI and professionals who wish to\\nupskill or change their domain to analytics and emerging technologies are free to apply.\\nAn Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Math's and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA\\nSkills relating to Mathematics/Statistics.\\nNatural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization\\nGood verbal and written communication skills\\nAbility to understand domains in businesses across various sectors\\n\\n\\nSelection procedure includes\\n\\nAptitude Test & Communication Exam - Online / Offline\\nSQL/Python test - Online / Offline\\n\\nCandidates who clears the above will have one-one discussion with our Career Guidance Manager for further evaluation and processing of your Resume.\\n\\n\\nAll the Shortlisted candidates will be eligible to continue the corporate training with CAIA\\nWhat you can expect from us?\\n\\nYou will get trained on the following modules for a period of 12-14 weeks:\\n\\nSQL & PLSQL\\nData Wrangling using Python\\nData Visualization Using Power-BI\\nStatistics for Machine Learning\\nArtificial Intelligence, Data Interpretation\\nSupervised & Unsupervised Learning,\\nNLP & Deep Learning\\nCloud Data Lake\\nBusiness intelligence & Data Visualization\\nSimulation Projects\\nExpected Outcome?\\n\\nAt the end of the Training you are expected to be well versed with the following:\\n\\nAnalysis of large and complex data sets from multiple sources\\nDevelopment and evaluation of data analytics models, algorithms and solutions\\nUnderstanding/implementation of ML algorithms, performance tuning and reporting\\nImplementation of algorithms to mine targeted data and the ability to convert data in to a business story\\nTranslation of business requirements into technical requirements; Data extraction, preparation and transformation\\nIdentification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organization\\nRequirement Analysis and communication of findings in the form of a meaningful story with the stakeholders\\nFinding analytical solutions to abstract business issues.\\nApply objective analysis of facts before coming to a conclusion\\n\\nAbout CAIA - Inflexion Analytix Private Limited\\n\\nCenter for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay.\\nDigital leaders - 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advance Analytics solutions for Fortune 500 companies.\\nOur Website : http://www.centerforaia.com/\\n\\nhttps://inflexion-analytix-private-limited.business.site/?m=true\\n\\nCenter for Artificial Intelligence & Advanced Analytics (CAIA) focuses on the following:\\n\\n1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics\\n2. Advanced Training programs for readying the future ready workforce\\n3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science.\",\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'Serve as primary technical lead on all phases of the projects from providing solutioning, experimentation and deployment.\\nWilling to get your hands dirty with data analysis as well as be comfortable delegating tasks to junior members on the project team, thus providing technical guidance and oversight to the overall project.\\nHands-on solutioning within the chosen AI platform to partner with both customer and internal data solution architects.\\nMust Have\\n8 years of experience delivering results from advanced analytics projects; with at least 2 years experience leading a project or large workstream\\nExperience working on data analytics problems in commercial problems space such as pricing, supply chain, marketing or customer experience. Proven track record with building and deploying supervised classification, regression, deep learning and unsupervised clustering models and time series analysis.\\n5 years of Knowledge and or experience with data transformations using SQL, leveraging SAS or SAS Viya platform.\\nStatistical model building with 5 years of experience\\nBasic understanding of machine learning models development in python and leveraging AWS.\\nBachelors Degree in Engineering, Mathematics Analytics, Economics or Business\\nNice to Have\\n5 years of Knowledge and experience with SAS or SAS Viya platform\\nExperience working with remote teams spread across the globe\\nMachine Learning modelling experience\\nPython programming to build ML models\\nAWS or equivalent other cloud based services knowledge SAS EG\\nExperience working in a data analytics COE or in an analytics consulting company',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For this task we have to scrap url for each job\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "url_job=[]\n",
    "for i in title:\n",
    "    url_job.append(i.get_attribute('href'))\n",
    "\n",
    "for k in url_job[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(k)\n",
    "        descript=driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\").text\n",
    "        desc.append(descript)\n",
    "    except NoSuchElementException:\n",
    "        desc.append('NA')\n",
    "\n",
    "desc=desc[:10]\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job Role : Data Scientist/Data Analyst /Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>RedBus</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immediate job opening - Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>RedBus</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Serve as primary technical lead on all phases ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VP - Sr. Data Scientist For Morgan Stanley, Ba...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Morgan Stanley Advantage Services</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>bd</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>FICO</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Global Talent Pool</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                              Senior Data Scientist   \n",
       "2      Immediate job opening - Senior Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4  VP - Sr. Data Scientist For Morgan Stanley, Ba...   \n",
       "5                                Lead Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7                                Lead Data Scientist   \n",
       "8                                     data scientist   \n",
       "9  Data analytics / Data scientist intern (work f...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "\n",
       "                              Company  \\\n",
       "0  Inflexion Analytix Private Limited   \n",
       "1                              RedBus   \n",
       "2                              RedBus   \n",
       "3                   Fractal Analytics   \n",
       "4   Morgan Stanley Advantage Services   \n",
       "5                                  bd   \n",
       "6                                FICO   \n",
       "7                   Fractal Analytics   \n",
       "8                  Global Talent Pool   \n",
       "9                      TalkValley LLC   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job Role : Data Scientist/Data Analyst /Busine...  \n",
       "1                                                 NA  \n",
       "2                                                 NA  \n",
       "3  Serve as primary technical lead on all phases ...  \n",
       "4                                                 NA  \n",
       "5                                                 NA  \n",
       "6                                                 NA  \n",
       "7                                                 NA  \n",
       "8                                                 NA  \n",
       "9                                                 NA  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Scientist={'Job':job,'Location':loc,\n",
    "              'Company':comp,'Job Description':desc}\n",
    "Data_Scientist=pd.DataFrame(data=Data_Scientist)\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Enter “Data Scientist” in “Skill,Designations,Companies” field ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//input[@class='sugInp']\").send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='btn']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then apply the location filter and salary filter by checking the respective boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying filter for loaction 'Delhi/NCR'\n",
    "\n",
    "driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i\").click()\n",
    "time.sleep(4)\n",
    "\n",
    "#Applying fliter for salary '3-6 lakhs'\n",
    "\n",
    "driver.find_element_by_xpath(\"//label[@for='chk-3-6 Lakhs-ctcFilter-']/i\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are hiring- Data Scientist +Python- Noida</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Milliman India Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst/Scientist Big Data, Statistical T...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>The Search House (A Div of JSD Search House Pv...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data analytics / Data scientist intern (work f...   \n",
       "2                                     Data Scientist   \n",
       "3              Chaayos is Looking For Data Scientist   \n",
       "4                              Junior Data Scientist   \n",
       "5       We are hiring- Data Scientist +Python- Noida   \n",
       "6                                     Data Scientist   \n",
       "7  Data Analyst/Scientist Big Data, Statistical T...   \n",
       "8                   Business Analyst- Data Scientist   \n",
       "9  Data Scientist - High growth VC backed Influen...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "2      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "3                                          New Delhi   \n",
       "4                             Noida(Sector-59 Noida)   \n",
       "5               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8                            Noida, Gurgaon/Gurugram   \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "\n",
       "                                             Company Experience  \n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs  \n",
       "1                                     TalkValley LLC    0-5 Yrs  \n",
       "2                                  Fractal Analytics    3-7 Yrs  \n",
       "3              Chaayos (Sunshine Teahouse Pvt. Ltd.)    0-5 Yrs  \n",
       "4                       R Systems International Ltd.    3-5 Yrs  \n",
       "5                             RANDSTAD INDIA PVT LTD    4-7 Yrs  \n",
       "6                             Milliman India Pvt Ltd    2-5 Yrs  \n",
       "7  The Search House (A Div of JSD Search House Pv...    2-7 Yrs  \n",
       "8                                              Wipro    2-5 Yrs  \n",
       "9                    Ravgins International Pvt. Ltd.    3-5 Yrs  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "Job=[]\n",
    "Loc=[]\n",
    "Comp=[]\n",
    "Exp=[]\n",
    "\n",
    "#scrapping job titles\n",
    "titles = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    Job.append(i.text)\n",
    "    Job=Job[:10]\n",
    "    \n",
    "#scrapping location\n",
    "loct=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in loct:\n",
    "    Loc.append(i.text)\n",
    "    Loc=Loc[:10]\n",
    "    \n",
    "#scrapping company\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in comp:\n",
    "    Comp.append(i.text)\n",
    "    Comp=Comp[:10]\n",
    "    \n",
    "#scrapping experience\n",
    "expe=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "for i in expe:\n",
    "    Exp.append(i.text)\n",
    "    Exp=Exp[:10]\n",
    "\n",
    "#Creating the DataFrame\n",
    "Data_Scientist_Delhi={'Job':Job,'Location':Loc,\n",
    "              'Company':Comp,'Experience':Exp}\n",
    "Data_Scientist_Delhi=pd.DataFrame(data=Data_Scientist_Delhi)\n",
    "Data_Scientist_Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "\n",
    "#### This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. first get the webpage https://www.glassdoor.co.in/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.glassdoor.co.in/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#Entering Data Scientist in Job field\n",
    "driver.find_element_by_xpath(\"//input[@id='sc.keyword']\").send_keys('Data Scientist')\n",
    "\n",
    "#To ender 'Noida' in loaction field, I have to delete 'Mumbai' which is auto populated.\n",
    "driver.find_element_by_xpath('//input[@id=\"sc.location\"]').clear()\n",
    "driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then scrape the data for the first 10 jobs results you get in the above shown page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Days Posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taboola</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bechtel</td>\n",
       "      <td>14d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Patterns</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>20d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>12d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>10d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>12d</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>12d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Team Computers</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name Days Posted Rating\n",
       "0                   Taboola          4d    4.2\n",
       "1                   Bechtel         14d    3.9\n",
       "2             Data Patterns         24h    3.0\n",
       "3  Lantern Digital Services          6d    3.5\n",
       "4            Biz2Credit Inc         20d    3.7\n",
       "5           Priority Vendor         12d    3.7\n",
       "6                  Ericsson         10d    4.1\n",
       "7      Gauge Data Solutions         12d    3.0\n",
       "8                     Crowe         12d    3.8\n",
       "9            Team Computers         24h    4.1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "c_name=[]\n",
    "days=[]\n",
    "rating=[]\n",
    "\n",
    "#scrapping company name\n",
    "companies=driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "for i in companies:\n",
    "    c_name.append(i.text)\n",
    "    c_name=c_name[:10]\n",
    "\n",
    "#scrapping the number of days before it was posted\n",
    "day=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "for i in day:\n",
    "    days.append(i.text)\n",
    "    days=days[:10]\n",
    "\n",
    "ratings=driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column css-x75kgh e1rrn5ka3']\")\n",
    "for i in ratings:\n",
    "    rating.append(i.text)\n",
    "    rating=rating[:10]\n",
    "    \n",
    "#Creating the DataFrame\n",
    "\n",
    "DS_Glassdoor={'Company Name':c_name,'Days Posted':days,'Rating':rating}\n",
    "DS_Glassdoor=pd.DataFrame(data=DS_Glassdoor)\n",
    "DS_Glassdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "###### You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "\n",
    "driver.find_element_by_xpath(\"//input[@name='sc.keyword']\").send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//input[@id='LocationSearch']\").clear()\n",
    "driver.find_element_by_xpath(\"//input[@id='LocationSearch']\").send_keys('Noida')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>17 salaries</td>\n",
       "      <td>₹ 6,15,289/yr</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,250K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹ 9,00,000/yr</td>\n",
       "      <td>₹587K</td>\n",
       "      <td>₹2,734K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,48,366/yr</td>\n",
       "      <td>₹578K</td>\n",
       "      <td>₹2,217K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 7,39,238/yr</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,615K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,41,763/yr</td>\n",
       "      <td>₹451K</td>\n",
       "      <td>₹11,640K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 13,38,279/yr</td>\n",
       "      <td>₹1,071K</td>\n",
       "      <td>₹1,523K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 13,28,697/yr</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹2,152K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,16,495/yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,467K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,42,356/yr</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,812K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,46,073/yr</td>\n",
       "      <td>₹576K</td>\n",
       "      <td>₹1,523K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company name Number of salaries  Average Salary Min Salary  \\\n",
       "0  Tata Consultancy Services        17 salaries   ₹ 6,15,289/yr      ₹343K   \n",
       "1                        IBM        15 salaries   ₹ 9,00,000/yr      ₹587K   \n",
       "2                  Accenture        14 salaries  ₹ 11,48,366/yr      ₹578K   \n",
       "3         Ericsson-Worldwide        14 salaries   ₹ 7,39,238/yr      ₹355K   \n",
       "4                  Delhivery        14 salaries  ₹ 12,41,763/yr      ₹451K   \n",
       "5         UnitedHealth Group        11 salaries  ₹ 13,38,279/yr    ₹1,071K   \n",
       "6     Optum Global Solutions         9 salaries  ₹ 13,28,697/yr      ₹350K   \n",
       "7         Valiance Solutions         9 salaries   ₹ 8,16,495/yr      ₹502K   \n",
       "8              ZS Associates         8 salaries  ₹ 11,42,356/yr      ₹202K   \n",
       "9                EXL Service         8 salaries  ₹ 11,46,073/yr      ₹576K   \n",
       "\n",
       "  Max Salary  \n",
       "0    ₹1,250K  \n",
       "1    ₹2,734K  \n",
       "2    ₹2,217K  \n",
       "3    ₹1,615K  \n",
       "4   ₹11,640K  \n",
       "5    ₹1,523K  \n",
       "6    ₹2,152K  \n",
       "7    ₹1,467K  \n",
       "8    ₹1,812K  \n",
       "9    ₹1,523K  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "c=[]\n",
    "mins=[]\n",
    "maxs=[]\n",
    "avg=[]\n",
    "num=[]\n",
    "\n",
    "#scrapping company name\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "    c.append(i.text)\n",
    "    c=c[:10]\n",
    "\n",
    "#scrapping min salary\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\"):\n",
    "    mins.append(i.text)\n",
    "    mins=mins[:10]\n",
    "\n",
    "#scrapping max salary\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\"):\n",
    "    maxs.append(i.text)\n",
    "    maxs=maxs[:10]\n",
    "    \n",
    "#scrapping average salary    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\"):\n",
    "    avg.append(i.text.replace('\\n',''))\n",
    "    avg=avg[:10]\n",
    "\n",
    "#scrapping number of salaries\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "    num.append(i.text)\n",
    "    num=num[:10]\n",
    "    \n",
    "#creating a dataframe for #Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "\n",
    "DS_Sal={'Company name':c,'Number of salaries':num,'Average Salary':avg,\n",
    "       'Min Salary':mins,'Max Salary':maxs}\n",
    "DS_Sal=pd.DataFrame(data=DS_Sal)\n",
    "DS_Sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "driver.get('https://www.flipkart.com/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once the website opens we get the pop. To cancel the pop up\n",
    "driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon.\n",
    "\n",
    "driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys('sunglasses')\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Wayfarer Sunglasses ...</td>\n",
       "      <td>₹890</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹541</td>\n",
       "      <td>32% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹509</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Wayfarer Sunglasses ...</td>\n",
       "      <td>₹890</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹331</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹331</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Aviator, Wayfarer Sunglasses (Fr...</td>\n",
       "      <td>₹213</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹751</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                        Description Price  \\\n",
       "0   VINCENT CHASE  by Lenskart UV Protection Wayfarer Sunglasses ...  ₹890   \n",
       "1       ROYAL SON         UV Protection Retro Square Sunglasses (54)  ₹699   \n",
       "2        Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹541   \n",
       "3        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹509   \n",
       "4      PHENOMENAL  UV Protection Retro Square Sunglasses (Free Size)  ₹399   \n",
       "..            ...                                                ...   ...   \n",
       "95  VINCENT CHASE  by Lenskart UV Protection Wayfarer Sunglasses ...  ₹890   \n",
       "96         PIRASO              UV Protection Aviator Sunglasses (58)  ₹331   \n",
       "97         PIRASO       UV Protection Aviator Sunglasses (Free Size)  ₹331   \n",
       "98        DEIXELS  UV Protection Aviator, Wayfarer Sunglasses (Fr...  ₹213   \n",
       "99       Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹751   \n",
       "\n",
       "   Discount  \n",
       "0   55% off  \n",
       "1   65% off  \n",
       "2   32% off  \n",
       "3   36% off  \n",
       "4   80% off  \n",
       "..      ...  \n",
       "95  55% off  \n",
       "96  87% off  \n",
       "97  79% off  \n",
       "98  82% off  \n",
       "99  16% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. after that you will reach to a webpage having a lot of sunglasses. \n",
    "#From this page you can scrap the required data as usual.\n",
    "\n",
    "b=[]\n",
    "pdis=[]\n",
    "pr=[]\n",
    "dis=[]\n",
    "\n",
    "#scrapping the brand name\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        b.append(j.text)\n",
    "        b=b[:100]\n",
    "        \n",
    "#scrapping the product description\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        pdis.append(j.text)\n",
    "        pdis=pdis[:100]\n",
    "\n",
    "#scrapping the product price\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        pr.append(j.text)\n",
    "        pr=pr[:100]\n",
    "\n",
    "#scrapping the product discount\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        dis.append(j.text)\n",
    "        dis=dis[:100]\n",
    "\n",
    "#clicking on the next page\n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "#creating the dataframe\n",
    "Flipkart_Sun={'Brand':b,'Description':pdis,'Price':pr,'Discount':dis}\n",
    "Flipkart_Sun=pd.DataFrame(data=Flipkart_Sun)\n",
    "Flipkart_Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "#1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on all reviews\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5       Great product   \n",
       "3       5   Worth every penny   \n",
       "4       5           Fabulous!   \n",
       "..    ...                 ...   \n",
       "95      4         Good choice   \n",
       "96      5  Highly recommended   \n",
       "97      5    Perfect product!   \n",
       "98      5    Perfect product!   \n",
       "99      5   Worth every penny   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  So far it’s been an AMAZING experience coming ...  \n",
       "96  iphone 11 is a very good phone to buy only if ...  \n",
       "97  It’s a must buy who is looking for an upgrade ...  \n",
       "98  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "99  Best budget Iphone till date ❤️ go for it guys...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the empty list to store the data\n",
    "\n",
    "rating=[]\n",
    "summ=[]\n",
    "full=[]\n",
    "\n",
    "for i in range(0,11):\n",
    "    \n",
    "    #scrapping the rating\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        rating.append(j.text)\n",
    "        rating=rating[:100]\n",
    "    \n",
    "    #scrapping the sunn\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        summ.append(j.text)\n",
    "        summ=summ[:100]\n",
    "\n",
    "    #scrapping the full review\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        full.append(j.text)\n",
    "        full=full[:100]\n",
    "\n",
    "#creating the dataframe\n",
    "iphone_reviews={'Rating':rating,'Review Summary':summ,'Full Review':full}\n",
    "iphone_reviews=pd.DataFrame(data=iphone_reviews)\n",
    "iphone_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEATHERKRAFT</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹296</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>BMW MMS Future Kart Cat Sneakers For Men</td>\n",
       "      <td>₹3,500</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers White Shoes For Men And Boys S...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUSON</td>\n",
       "      <td>Gym/Walking/Running Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-322 Sneakers For Men</td>\n",
       "      <td>₹769</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹3,599</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Summits - Brisbane Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Anzarun Lite Sneakers For Men</td>\n",
       "      <td>₹1,979</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ORICUM</td>\n",
       "      <td>Rebound BBX Mesh IDP Sneakers For Men</td>\n",
       "      <td>₹629</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NIKE</td>\n",
       "      <td>Oricum Sports (Walking &amp; Gym Shoes) Running, L...</td>\n",
       "      <td>₹1,932</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                        Description   Price  \\\n",
       "0   LEATHERKRAFT                                   Sneakers For Men    ₹296   \n",
       "1           PUMA           BMW MMS Future Kart Cat Sneakers For Men  ₹3,500   \n",
       "2   Robbie jones  Casual Sneakers White Shoes For Men And Boys S...    ₹499   \n",
       "3          SUSON               Gym/Walking/Running Sneakers For Men    ₹399   \n",
       "4          SPARX                            SM-322 Sneakers For Men    ₹769   \n",
       "..           ...                                                ...     ...   \n",
       "95      Skechers                                   Sneakers For Men  ₹3,599   \n",
       "96      URBANBOX                Summits - Brisbane Sneakers For Men    ₹199   \n",
       "97        ADIDAS                      Anzarun Lite Sneakers For Men  ₹1,979   \n",
       "98        ORICUM              Rebound BBX Mesh IDP Sneakers For Men    ₹629   \n",
       "99          NIKE  Oricum Sports (Walking & Gym Shoes) Running, L...  ₹1,932   \n",
       "\n",
       "   Discount  \n",
       "0   70% off  \n",
       "1   49% off  \n",
       "2   50% off  \n",
       "3   60% off  \n",
       "4   23% off  \n",
       "..      ...  \n",
       "95  57% off  \n",
       "96  59% off  \n",
       "97  61% off  \n",
       "98  57% off  \n",
       "99  49% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=[]\n",
    "productdis=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#scrapping the brand name\n",
    "for i in range(0,4):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand.append(j.text)\n",
    "        brand=brand[:100]\n",
    "        \n",
    "#scrapping the product description\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        productdis.append(j.text)\n",
    "        productdis=productdis[:100]\n",
    "\n",
    "#scrapping the product price\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price.append(j.text)\n",
    "        price=price[:100]\n",
    "\n",
    "#scrapping the product discount\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        discount.append(j.text)\n",
    "        discount=discount[:100]\n",
    "\n",
    "#clicking on the next page\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "            \n",
    "#creating the dataframe\n",
    "Flipkart_Sneakers={'Brand':brand,'Description':productdis,'Price':price,'Discount':discount}\n",
    "Flipkart_Sneakers=pd.DataFrame(data=Flipkart_Sneakers)\n",
    "Flipkart_Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9: Go to the link - myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price filter (there is no price filter for 6649 to 13099 hence will filter it with 6612 to 13075)\n",
    "\n",
    "driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "#color filter\n",
    "driver.find_element_by_xpath(\"//span[@data-colorhex='black']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex LEBRON XVIII Basketball</td>\n",
       "      <td>Rs. 12316Rs. 17595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex COSMIC UNITY Basketball</td>\n",
       "      <td>Rs. 11470Rs. 13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM FREAK 2 Basketball</td>\n",
       "      <td>Rs. 7721Rs. 10295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JOYRIDE Running Shoes</td>\n",
       "      <td>Rs. 11246Rs. 14995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged RC Sportstyle Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VIVA Sneakers</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                      Description               Price\n",
       "0           Nike   Unisex LEBRON XVIII Basketball  Rs. 12316Rs. 17595\n",
       "1           Nike   Unisex COSMIC UNITY Basketball  Rs. 11470Rs. 13495\n",
       "2           Nike      Men ZOOM FREAK 2 Basketball   Rs. 7721Rs. 10295\n",
       "3           Nike        Men JOYRIDE Running Shoes  Rs. 11246Rs. 14995\n",
       "4           Nike      Men JORDAN DELTA Basketball           Rs. 12495\n",
       "..           ...                              ...                 ...\n",
       "95  Hush Puppies        Men Leather Formal Derbys            Rs. 6999\n",
       "96  UNDER ARMOUR   Charged RC Sportstyle Sneakers            Rs. 8999\n",
       "97  Hush Puppies  Men Solid Leather Formal Derbys            Rs. 9999\n",
       "98          FILA                   Women Sneakers            Rs. 8999\n",
       "99          Nike      Women AIR MAX VIVA Sneakers           Rs. 12495\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe to store the data\n",
    "shoe=[]\n",
    "ssdesc=[]\n",
    "shoeprice=[]\n",
    "\n",
    "for i in range(0,2):\n",
    "    time.sleep(2)\n",
    "    for i in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        shoe.append(i.text)\n",
    "        shoe=shoe[:100]\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        ssdesc.append(i.text)\n",
    "        ssdesc=ssdesc[:100]\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\"):\n",
    "        shoeprice.append(i.text)\n",
    "        shoeprice=shoeprice[:100]\n",
    "        \n",
    "    #going to the next page\n",
    "    driver.find_element_by_xpath(\"//a[@rel='next']\").click()\n",
    "    \n",
    "#creating the dataframe\n",
    "Myntra_Shoes={'Brand':shoe,'Description':ssdesc,'Price':shoeprice}\n",
    "Myntra_Shoes=pd.DataFrame(data=Myntra_Shoes)\n",
    "Myntra_Shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the laptop under search\n",
    "driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking the search button\n",
    "\n",
    "driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the filter for “Intel Core i7” and “Intel Core i9” \n",
    "\n",
    "driver.find_element_by_xpath(\"//*[@id='p_n_feature_thirteen_browse-bin/12598163031']/span/a\").click()\n",
    "time.sleep(4)\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[@id='p_n_feature_thirteen_browse-bin/16757432031']/span/a\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>3.2 out of 5 stars</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>54,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "      <td>26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>91,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...</td>\n",
       "      <td>2.3 out of 5 stars</td>\n",
       "      <td>96,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>78,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...  3.2 out of 5 stars   \n",
       "1  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...  4.2 out of 5 stars   \n",
       "2  Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...  4.4 out of 5 stars   \n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.5 out of 5 stars   \n",
       "4  HP Pavilion (2021) Thin & Light 11th Gen Core ...  3.1 out of 5 stars   \n",
       "5  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  4.1 out of 5 stars   \n",
       "6  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  5.0 out of 5 stars   \n",
       "7  Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...  4.3 out of 5 stars   \n",
       "8  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...  2.3 out of 5 stars   \n",
       "9  (Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...  3.8 out of 5 stars   \n",
       "\n",
       "    Price  \n",
       "0  83,990  \n",
       "1  97,990  \n",
       "2  54,999  \n",
       "3  84,990  \n",
       "4  26,990  \n",
       "5  86,990  \n",
       "6  77,990  \n",
       "7  91,490  \n",
       "8  96,000  \n",
       "9  78,990  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping the data\n",
    "\n",
    "#creating the empty list to enter the data\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]\n",
    "\n",
    "#scrapping the title\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]'):\n",
    "    Title.append(i.text)\n",
    "    Title=Title[:10]\n",
    "\n",
    "#scrapping the rating\n",
    "\n",
    "Rating=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')  \n",
    "for i in Rating:\n",
    "    Ratings.append(i.get_attribute('aria-label'))\n",
    "    Ratings=Ratings[:10]\n",
    "    \n",
    "#scrapping the Price\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]'):\n",
    "    Price.append(i.text)\n",
    "    Price=Price[:10]\n",
    "    \n",
    "#creating the dataframe\n",
    "Amazon_laptop={'Title':Title,'Ratings':Ratings,'Price':Price}\n",
    "Amazon_laptop=pd.DataFrame(data=Amazon_laptop)\n",
    "Amazon_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
