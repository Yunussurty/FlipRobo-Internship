{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Scraping and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be scraping the news from economic times for the month of August 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libaries. We will be using selenium webdriver for this\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the year you want to scrap the new for: 2020\n",
      "Enter the month in digit only ,i.e for Jan enter 1 or for Nov enter 11: 8\n",
      "The number of days the month have: 31\n"
     ]
    }
   ],
   "source": [
    "#creating the input function for the data to be scrape\n",
    "\n",
    "a=input('Enter the year you want to scrap the new for: ')\n",
    "b=input('Enter the month in digit only ,i.e for Jan enter 1 or for Nov enter 11: ')\n",
    "c=input('The number of days the month have: ')\n",
    "url='https://economictimes.indiatimes.com/archive/year-{},month-{}.cms'.format(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://economictimes.indiatimes.com/archive/year-2020,month-8.cms\n"
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "#1st we will scrape all the dates url\n",
    "date_urls=[]\n",
    "dates=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//td[@align='center']/a\"):\n",
    "    date_urls.append(i.get_attribute('href'))\n",
    "for i in date_urls:\n",
    "    if i not in dates:\n",
    "        dates.append(i)\n",
    "if len(dates)!=c:\n",
    "    dates=dates[1:]\n",
    "\n",
    "print(len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the empty list for date to be store\n",
    "news_date=[]\n",
    "news_author=[]\n",
    "news_topic=[]\n",
    "news_headlines=[]\n",
    "news_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating the function\n",
    "\n",
    "capa = DesiredCapabilities.CHROME\n",
    "capa[\"pageLoadStrategy\"] = \"eager\" #since economictimes has long loading time. This command will start scraping once \n",
    "driver = webdriver.Chrome(desired_capabilities=capa)  #the html is loaded.\n",
    "\n",
    "new_dates=[]\n",
    "for m in range(1,len(31)):\n",
    "    driver.get(dates[m-1])\n",
    "    \n",
    "    for j in driver.find_elements_by_xpath('//ul[@class=\"content\"]/li/a'):\n",
    "        new_dates.append(j.get_attribute('href')) #appending all the news link of the particular day\n",
    "    for k in new_dates:\n",
    "        driver.get(k)\n",
    "        \n",
    "    \n",
    "               \n",
    "        date=driver.find_elements_by_xpath('//div[@class=\"dtc vam artByline\"]/time')\n",
    "        for i in date:\n",
    "            if i.text is None:\n",
    "                news_date.append(\"--\")\n",
    "            else:\n",
    "                news_date.append(i.text.split(': ')[1])\n",
    "        \n",
    "#certain news only for paid subscribers and it will create the uneven list. The below command will ignore such page\n",
    "        if len(news_date)!=len(news_topic)+1:\n",
    "            news_date.append(\"--\")\n",
    "            news_author.append('--')\n",
    "            news_topic.append(\"--\")\n",
    "            news_headlines.append(\"--\")\n",
    "            news_description.append(\"--\")\n",
    "            continue            \n",
    "        \n",
    "        author=driver.find_elements_by_xpath('//span[@class=\"ag\"]')\n",
    "        for i in author:\n",
    "            news_author.append(i.text)\n",
    "                \n",
    "           \n",
    "        topic=driver.find_elements_by_xpath('//div[@class=\"clr breadCrumb contentwrapper\"]/span[3]')\n",
    "        for i in topic:\n",
    "            news_topic.append(i.text)\n",
    "                \n",
    "        \n",
    "        headlines=driver.find_elements_by_xpath('//h1[@class=\"artTitle font_faus\"]')\n",
    "        for i in headlines:\n",
    "            news_headlines.append(i.text)\n",
    "        \n",
    "        time.sleep(2) \n",
    "        try:\n",
    "            try:news_description.append(driver.find_element_by_xpath(\"//div[@class='artText medium']\").text.replace('\\n','').replace('\\'',''))\n",
    "            except:news_description.append(driver.find_element_by_xpath(\"//div[@class='artText m']\").text.replace('\\n','').replace('\\'',''))    \n",
    "        except NoSuchElementException:\n",
    "            news_description.append(\"--\")\n",
    "                        \n",
    "        print((len(news_date),len(news_author),len(news_topic),len(news_headlines),len(news_description)))\n",
    "    \n",
    "    print('Scraping of date', m, 'completed')\n",
    "    new_dates=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create the data frame\n",
    "df=pd.DataFrame({\"Date and time of upload\":news_date,\"Author name\":news_author,\"Topic or Vertical\":news_topic,\n",
    "                 \"Headlines\":news_headlines,\"Description\":news_description})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the null values from the dataframe\n",
    "index_names = df[ df['Description'] == \"--\" ].index\n",
    "df.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the csv for scrape date\n",
    "df.to_csv('News.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the JSON file\n",
    "df.to_json('News.json', orient = 'split', compression = 'infer', index = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the excel file\n",
    "df.to_excel('NewsAug20.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('News.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date and time of upload</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Topic or Vertical</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aug 01, 2020, 12:03 AM IST</td>\n",
       "      <td>ET Bureau</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Erratic rainfall hits crop planting as sowing ...</td>\n",
       "      <td>NEW DELHI: Erratic rainfall has slowed down cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aug 01, 2020, 12:03 AM IST</td>\n",
       "      <td>ET Bureau</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Continuation of safeguard duties on imports fr...</td>\n",
       "      <td>NEW DELHI: The governments decision to continu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Aug 01, 2020, 12:47 AM IST</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>International</td>\n",
       "      <td>Microsoft is said to be in talks to buy TikTok...</td>\n",
       "      <td>By Kurt WagnerMicrosoft Corp. is exploring an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aug 01, 2020, 07:22 AM IST</td>\n",
       "      <td>ET Bureau</td>\n",
       "      <td>Cons. Products</td>\n",
       "      <td>Import restrictions on colour television to gi...</td>\n",
       "      <td>New Delhi: TV manufacturers like Chinas Xiaomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aug 01, 2020, 07:45 AM IST</td>\n",
       "      <td>ET Bureau</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Rajasthan political crisis: BJP hopes rest on ...</td>\n",
       "      <td>New Delhi: Rajasthan governor Kalraj Mishra ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>9306</td>\n",
       "      <td>Sep 01, 2020, 05:31 PM IST</td>\n",
       "      <td>PTI</td>\n",
       "      <td>GST</td>\n",
       "      <td>Govt extends FY20 GST return filing date for c...</td>\n",
       "      <td>New Delhi:The government on Monday extended by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9307</th>\n",
       "      <td>9307</td>\n",
       "      <td>Aug 31, 2020, 10:48 PM IST</td>\n",
       "      <td>ET Bureau</td>\n",
       "      <td>Services</td>\n",
       "      <td>Office space leasing dropped by 60% in six cit...</td>\n",
       "      <td>NEW DELHI: Office space absorption in six majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>9308</td>\n",
       "      <td>Aug 31, 2020, 10:55 PM IST</td>\n",
       "      <td>ET Bureau</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>RBI may propose tweaks to Sarfaesi Act to brid...</td>\n",
       "      <td>Mumbai: The Reserve Bank of India may propose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>9309</td>\n",
       "      <td>Aug 31, 2020, 10:53 PM IST</td>\n",
       "      <td>ET Bureau</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Some relief as Tamil Nadu reports under 6,000 ...</td>\n",
       "      <td>Chennai: Tamil Nadu saw under 6000 cases on Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>9310</td>\n",
       "      <td>Aug 31, 2020, 11:00 PM IST</td>\n",
       "      <td>Mediawire</td>\n",
       "      <td>International</td>\n",
       "      <td>Hiring spree: 670 professionals hired through ...</td>\n",
       "      <td>Hiring spree kicks in: 670 professionals got h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     Date and time of upload Author name Topic or Vertical  \\\n",
       "0              0  Aug 01, 2020, 12:03 AM IST   ET Bureau          Politics   \n",
       "1              1  Aug 01, 2020, 12:03 AM IST   ET Bureau           Economy   \n",
       "2              2  Aug 01, 2020, 12:47 AM IST   Bloomberg     International   \n",
       "3              3  Aug 01, 2020, 07:22 AM IST   ET Bureau    Cons. Products   \n",
       "4              4  Aug 01, 2020, 07:45 AM IST   ET Bureau          Politics   \n",
       "...          ...                         ...         ...               ...   \n",
       "9306        9306  Sep 01, 2020, 05:31 PM IST         PTI               GST   \n",
       "9307        9307  Aug 31, 2020, 10:48 PM IST   ET Bureau          Services   \n",
       "9308        9308  Aug 31, 2020, 10:55 PM IST   ET Bureau            Stocks   \n",
       "9309        9309  Aug 31, 2020, 10:53 PM IST   ET Bureau          Politics   \n",
       "9310        9310  Aug 31, 2020, 11:00 PM IST   Mediawire     International   \n",
       "\n",
       "                                              Headlines  \\\n",
       "0     Erratic rainfall hits crop planting as sowing ...   \n",
       "1     Continuation of safeguard duties on imports fr...   \n",
       "2     Microsoft is said to be in talks to buy TikTok...   \n",
       "3     Import restrictions on colour television to gi...   \n",
       "4     Rajasthan political crisis: BJP hopes rest on ...   \n",
       "...                                                 ...   \n",
       "9306  Govt extends FY20 GST return filing date for c...   \n",
       "9307  Office space leasing dropped by 60% in six cit...   \n",
       "9308  RBI may propose tweaks to Sarfaesi Act to brid...   \n",
       "9309  Some relief as Tamil Nadu reports under 6,000 ...   \n",
       "9310  Hiring spree: 670 professionals hired through ...   \n",
       "\n",
       "                                            Description  \n",
       "0     NEW DELHI: Erratic rainfall has slowed down cr...  \n",
       "1     NEW DELHI: The governments decision to continu...  \n",
       "2     By Kurt WagnerMicrosoft Corp. is exploring an ...  \n",
       "3     New Delhi: TV manufacturers like Chinas Xiaomi...  \n",
       "4     New Delhi: Rajasthan governor Kalraj Mishra ha...  \n",
       "...                                                 ...  \n",
       "9306  New Delhi:The government on Monday extended by...  \n",
       "9307  NEW DELHI: Office space absorption in six majo...  \n",
       "9308  Mumbai: The Reserve Bank of India may propose ...  \n",
       "9309  Chennai: Tamil Nadu saw under 6000 cases on Mo...  \n",
       "9310  Hiring spree kicks in: 670 professionals got h...  \n",
       "\n",
       "[9290 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9290, 9290, 9290, 9290, 9290)\n"
     ]
    }
   ],
   "source": [
    "print((len(news_date),len(news_author),len(news_topic),len(news_headlines),len(news_description)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "news_date = df[\"Date and time of upload\"].tolist()\n",
    "news_author = df[\"Author name\"].tolist()\n",
    "news_topic = df[\"Topic or Vertical\"].tolist()\n",
    "news_headlines = df[\"Headlines\"].tolist()\n",
    "news_description = df[\"Description\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
